{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jzoRXn31ogq"
      },
      "source": [
        "#Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QVbLmsdXCH9",
        "outputId": "7eea93ba-fa14-4d83-ba2d-58884ef39db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROuYgZxugXhX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler    \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "import nltk\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwrH0Aw_t0t"
      },
      "source": [
        "#Download nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ag20JAs_tav",
        "outputId": "ea031b31-62eb-461d-f35c-eb3b9ed294cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjStAMfj__fu"
      },
      "source": [
        "#Splitting , Balancing and  Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeIsPoUN__Ou"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
        "\n",
        "\n",
        "training_data_review=data\n",
        "\n",
        "training_data_review['tokenized'] = training_data_review['review'].apply(word_tokenize)\n",
        "\n",
        "training_data_review['review_lowercase']=training_data_review['tokenized'].apply(lambda x : [word.lower() for word in x])\n",
        "punc = string.punctuation\n",
        "training_data_review['no_punc']=training_data_review['review_lowercase'].apply(lambda x: [word for word in x if word not in punc])\n",
        "stop_words = set(stopwords.words('english'))\n",
        "training_data_review['stopwords_removed'] = training_data_review['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "training_data_review.head()\n",
        "training_data_review['pos_tags'] = training_data_review['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "\n",
        "training_data_review['wordnet_pos'] = training_data_review['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
        "wnl = WordNetLemmatizer()\n",
        "training_data_review['lemmatized'] = training_data_review['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XJ625oY7oZG"
      },
      "outputs": [],
      "source": [
        "training_data_review['lemmatized']=training_data_review['lemmatized'].apply(lambda x:(\" \".join(x)))\n",
        "\n",
        "\n",
        "x_train, x_test,y_train,y_test = train_test_split(np.array(training_data_review['lemmatized']),np.array(training_data_review['sentiment']), test_size=0.2, random_state=70)\n",
        "x_train2,x_valid,y_train2,y_valid = train_test_split(x_train,y_train,test_size=0.125,random_state=70)\n",
        "#####IFCORRECT balance data\n",
        "training_data_review2=pd.DataFrame(x_train2.reshape(-1,1),columns=['review'])\n",
        "training_data_review2['sentiment']=pd.DataFrame(y_train2.reshape(-1,1))\n",
        "\n",
        "validation_data_review=pd.DataFrame(x_valid.reshape(-1,1),columns=[\"review\"])\n",
        "validation_data_review['sentiment']=pd.DataFrame(y_valid.reshape(-1,1))\n",
        "\n",
        "testing_data_review1=pd.DataFrame(x_test.reshape(-1,1),columns=[\"review\"])\n",
        "testing_data_review1['sentiment']=pd.DataFrame(y_test.reshape(-1,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IRxUG0NJp_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f860f733-b42d-4472-ec17-4eb79eebfbd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import gc\n",
        "del data\n",
        "del training_data_review\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1A5uAVu19ih"
      },
      "source": [
        "# Create Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK1fxaBejiGB"
      },
      "outputs": [],
      "source": [
        "labels={'negative':0,'positive':1}\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        self.labels = [labels[label] for label in df['sentiment']] #Extract the labels from the dataframe\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['review']]#Tokenize the reviews \n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels #Return the labels\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.labels)#Return the number of labels\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)#Return a batch of labels\n",
        "        batch_y = self.get_batch_labels(idx)#Return a batch of reviews\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12Mog6q2CS6"
      },
      "source": [
        "#Create the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF2wZ7yCjiIQ"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.1):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(p=dropout,inplace=False) #Required for regularization to reduce overfitting and is used to avoid overfitting by zeroing some elements from input tensors\n",
        "        self.linear_in = nn.Linear(768, 512)\n",
        "        self.relu=nn.ReLU()\n",
        "        self.linear_1 =nn.Linear(512, 256)\n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.linear_2 =nn.Linear(256, 128)\n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.linear_3 =nn.Linear(128, 64)\n",
        "        self.relu_3 = nn.ReLU()\n",
        "        self.linear_4 =nn.Linear(64,1)\n",
        "        \n",
        "\n",
        "    def forward(self, input_id, mask): \n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False) #pooled_output contains the CLS embedding\n",
        "        dropout_output = self.dropout(pooled_output)#Dropout to avoid overfitting\n",
        "        dropout_output =self.relu (self.linear_in(dropout_output))\n",
        "        dropout_output =self.relu_1 (self.linear_1(dropout_output))\n",
        "        dropout_output =self.relu_2 (self.linear_2(dropout_output))\n",
        "        dropout_output =self.relu_3 (self.linear_3(dropout_output))\n",
        "        dropout_output = (self.linear_4(dropout_output))\n",
        "\n",
        "        return dropout_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(y_test,y_predicted):\n",
        "  predicted_label=torch.round(torch.sigmoid(y_predicted))\n",
        "\n",
        "  no_correct_samples=(predicted_label==y_test).sum().float()\n",
        "\n",
        "  return no_correct_samples"
      ],
      "metadata": {
        "id": "zAEjHjwr7C2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9RJipQc2GfC"
      },
      "source": [
        "#Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ic6Ge6_jiK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c382be67-f563-4ba0-b6bc-9fcd18b1ee6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 500/500 [01:27<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.694                 | Train Accuracy:  0.478                 | Val Loss:  0.694                 | Val Accuracy:  0.455\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:28<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.693                 | Train Accuracy:  0.516                 | Val Loss:  0.694                 | Val Accuracy:  0.455\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:36<00:00,  5.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.693                 | Train Accuracy:  0.516                 | Val Loss:  0.695                 | Val Accuracy:  0.455\n",
            "1.0000000000000002e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:30<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.692                 | Train Accuracy:  0.516                 | Val Loss:  0.692                 | Val Accuracy:  0.455\n",
            "1.0000000000000002e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:30<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.683                 | Train Accuracy:  0.650                 | Val Loss:  0.680                 | Val Accuracy:  0.710\n",
            "1.0000000000000002e-06\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs,processed):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data) #Extracts the text and label from the given data\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=True)#While training a model,pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 1)\n",
        "    \n",
        "    if use_cuda:\n",
        "      model = model.cuda()\n",
        "      criterion = criterion.cuda()\n",
        "\n",
        "    min_loss=100000000000\n",
        "    current_loss=0\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(torch.float32)\n",
        "                train_label=train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                \n",
        "                batch_loss = criterion(output, train_label.unsqueeze(1))\n",
        "                total_loss_train += batch_loss.item()#Extract the loss as a float and add it to the total loss\n",
        "                \n",
        "               \n",
        "                acc = calculate_accuracy(train_label,output)\n",
        "               \n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()#zero out the accumulted gradients\n",
        "                batch_loss.backward()#Update weights and Biases\n",
        "                optimizer.step()#Perform a single optimization step\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():# Disable gradient calculation.\n",
        "            #Model is being validated so there is no need to calculate gradients. It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "                    val_label=val_label.to(torch.float32)\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "                    \n",
        "                    \n",
        "                    batch_loss = criterion(output, val_label.unsqueeze(1))\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    \n",
        "                    acc = calculate_accuracy(val_label,output)\n",
        "                    \n",
        "                    total_acc_val += acc\n",
        "\n",
        "            current_loss=total_loss_val#Calculate the total validation loss.\n",
        "            scheduler.step(current_loss)\n",
        "            if(current_loss<min_loss): \n",
        "                min_loss=current_loss\n",
        "                if(processed==1):\n",
        "                  PATH='model.pt'\n",
        "                elif(processed==0):\n",
        "                  PATH='model_up.pt'\n",
        "                torch.save({\n",
        "                  'epoch': epoch_num,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'loss': min_loss,\n",
        "                  }, PATH)\n",
        "                \n",
        "\n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "            \n",
        "            for param_group in optimizer.param_groups:\n",
        "              print(param_group['lr'])\n",
        "            gc.collect()\n",
        "            \n",
        "                  \n",
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-5\n",
        "processed=1\n",
        "\n",
        "\n",
        "train(model, training_data_review2.iloc[0:5000,:], validation_data_review.iloc[0:2000,:], LR, EPOCHS,processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKynQvLI2Jdh"
      },
      "source": [
        "#Evaluate The Model On Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbxxX3oXu0_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "bba806f5-8adf-4871-bef9-06df35d43db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      1.00      0.64        95\n",
            "    positive       0.00      0.00      0.00       105\n",
            "\n",
            "    accuracy                           0.48       200\n",
            "   macro avg       0.24      0.50      0.32       200\n",
            "weighted avg       0.23      0.47      0.31       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "      model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    y_pred = []\n",
        "    y_pred=torch.tensor(y_pred)\n",
        "    y_pred=y_pred.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              y_pred=torch.cat((y_pred,output))\n",
        "              output=(output>0.5).float()\n",
        "              acc = (output == test_label).sum()\n",
        "              \n",
        "              total_acc_test += acc\n",
        "        \n",
        "      \n",
        "        \n",
        "        test_data['sentiment'].replace({'positive':1,'negative':0},inplace=True)\n",
        "        y_test=test_data['sentiment'].to_numpy()\n",
        "        y_pred=torch.flatten(y_pred)\n",
        "        y_pred=y_pred.detach().cpu().numpy()\n",
        "        y_pred=np.where(y_pred > 0.5, 1, 0)\n",
        "        classes=['negative','positive']\n",
        "        \n",
        "        \n",
        "        net_classification_report=classification_report(y_test,y_pred,target_names=classes)    \n",
        "        print(net_classification_report)\n",
        "        conf_mat=confusion_matrix(y_test,y_pred)\n",
        "\n",
        "        \n",
        "        disp=ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=classes)\n",
        "        disp.plot()\n",
        "        plt.show()\n",
        "\n",
        "        gc.collect()\n",
        "    \n",
        "\n",
        "#Load Best Model\n",
        "PATH='model.pt'\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "#print the best model parameters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "evaluate(model, testing_data_review1.iloc[0:2000,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unpreprocessed Data"
      ],
      "metadata": {
        "id": "SY8Sj64qe3Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "data = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
        "x_train_up, x_test_up,y_train_up,y_test_up = train_test_split(np.array(data.iloc[:,:-1]),np.array(data['sentiment']), test_size=0.2, random_state=70)\n",
        "x_train2_up,x_valid_up,y_train2_up,y_valid_up = train_test_split(x_train_up,y_train_up,test_size=0.125,random_state=70)\n",
        "\n",
        "x_train2_up=pd.DataFrame(x_train2_up.reshape(-1,1),columns=['review'])\n",
        "x_train2_up['sentiment']=pd.DataFrame(y_train2_up.reshape(-1,1))\n",
        "\n",
        "x_valid_up=pd.DataFrame(x_valid_up.reshape(-1,1),columns=['review'])\n",
        "x_valid_up['sentiment']=pd.DataFrame(y_valid_up.reshape(-1,1))\n",
        "\n",
        "x_test_up=pd.DataFrame(x_test_up.reshape(-1,1),columns=['review'])\n",
        "x_test_up['sentiment']=pd.DataFrame(y_test_up.reshape(-1,1))\n"
      ],
      "metadata": {
        "id": "78eBdxWre2s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS = 5\n",
        "model_up = BertClassifier()\n",
        "LR = 1e-5\n",
        "processed=0\n",
        "\n",
        "train(model_up, x_train2_up.iloc[:5000,:], x_valid_up.iloc[:2000,:], LR, EPOCHS,processed)"
      ],
      "metadata": {
        "id": "T2Lcyo5se2vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b2849e-3595-44b2-f09a-4ac471f8d1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 500/500 [01:33<00:00,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.684                 | Train Accuracy:  0.572                 | Val Loss:  0.646                 | Val Accuracy:  0.730\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.561                 | Train Accuracy:  0.786                 | Val Loss:  0.493                 | Val Accuracy:  0.810\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.397                 | Train Accuracy:  0.840                 | Val Loss:  0.521                 | Val Accuracy:  0.790\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:32<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.258                 | Train Accuracy:  0.924                 | Val Loss:  0.597                 | Val Accuracy:  0.770\n",
            "1.0000000000000002e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.201                 | Train Accuracy:  0.946                 | Val Loss:  0.567                 | Val Accuracy:  0.795\n",
            "1.0000000000000002e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Best Model\n",
        "PATH='model_up.pt'\n",
        "checkpoint = torch.load(PATH)\n",
        "model_up.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "#print the best model parameters\n",
        "\n",
        "evaluate(model_up, x_test_up.iloc[:2000,:])"
      ],
      "metadata": {
        "id": "xPPF6qa3e2xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "8663dfcd-cd39-4010-86ba-a44f7c287a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.83      0.83        95\n",
            "    positive       0.85      0.85      0.85       105\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.84      0.84      0.84       200\n",
            "weighted avg       0.84      0.84      0.84       200\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment 4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}